import streamlit as st
import pandas as pd
import json
import os
import subprocess
import time
import altair as alt

# Config
LOG_FILE = "logs/metrics.jsonl"
JOB_SCRIPT = "job_launcher.sh"

st.set_page_config(page_title="RLAIF Control Center", layout="wide")
st.title("ğŸš€ RLAIF Training Control Center")

import shutil
import signal

# Detect Environment
HAS_SLURM = shutil.which("sbatch") is not None
MODE_LABEL = "Cluster" if HAS_SLURM else "Local"

# --- Sidebar: Job Control ---
st.sidebar.title(f"ğŸ® Control Panel ({MODE_LABEL})")

def run_command(cmd):
    try:
        result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        return f"Error: {e.stderr}"

# Local Process Helpers
PID_FILE = "local_run.pid"
import sys

# Local Process Helpers
PID_FILE = "local_run.pid"
import sys

def start_local(mode_arg="demo"):
    # Authenticate WandB for local run
    env = os.environ.copy()
    env["WANDB_API_KEY"] = "ef2da50d021e41130a9c9d762f7e56c79dbed703"
    env["WANDB_PROJECT"] = "rlaif-research"
    
    with open("local_log.txt", "w") as out:
        # Pass the selected mode
        proc = subprocess.Popen(
            [sys.executable, "train.py", "--mode", mode_arg], 
            stdout=out, 
            stderr=out,
            env=env
        )
        with open(PID_FILE, "w") as f:
            f.write(str(proc.pid))
    return f"Started Local Process (PID {proc.pid}) in {mode_arg.upper()} mode"

def stop_local():
    if os.path.exists(PID_FILE):
        try:
            with open(PID_FILE, "r") as f:
                pid = int(f.read().strip())
            os.kill(pid, signal.SIGTERM)
            os.remove(PID_FILE)
            return f"Killed PID {pid}"
        except Exception as e:
            return f"Error killing: {e}"
    return "No local PID found."

def check_local_status():
    if os.path.exists(PID_FILE):
        # Check if actually running
        try:
            with open(PID_FILE, "r") as f:
                pid = int(f.read().strip())
            os.kill(pid, 0) # Check existence
            return f"ğŸŸ¢ Running (PID {pid})"
        except OSError:
            return "ğŸ”´ Crashed/Stopped (Stale PID)"
    return "âšª Idle"


# Section 1: Actions
st.sidebar.markdown("### 1. Actions")
col_s1, col_s2 = st.sidebar.columns(2)

# Determine state
is_running = False
if HAS_SLURM:
    # Quick check (cached if possible, but for safety we run it)
    # We might rely on the labels from below, but let's do a quick check here
    check = run_command("squeue --me --noheader")
    if check and len(check.strip()) > 0:
        is_running = True
else:
    # Local check
    if os.path.exists(PID_FILE):
        try:
            with open(PID_FILE, "r") as f:
                pid = int(f.read().strip())
            os.kill(pid, 0)
            is_running = True
        except:
            is_running = False

with col_s1:
    btn_label = "â–¶ï¸ Start Job" if HAS_SLURM else "â–¶ï¸ Start Local"
    
    # Mode Selector
    if not HAS_SLURM:
        train_mode = st.radio("Training Mode", ["Demo (Fast)", "Full (Research)"], index=0)
        mode_arg = "demo" if "Demo" in train_mode else "research"
    else:
        mode_arg = "research" # Cluster always research
    
    if is_running:
        st.button("âš ï¸ Running...", disabled=True, help="Job is already active. Stop it first.")
    else:
        if st.button(btn_label, help=f"Start training on {MODE_LABEL}"):
            # 1. Logic: Only Clear Logs if Starting FRESH
            # If we have checkpoints, we want to append/persist history.
            has_checkpoints = False
            if os.path.exists("trainer_output"):
                import glob
                if glob.glob("trainer_output/checkpoint-*"):
                    has_checkpoints = True
            
            if not has_checkpoints and os.path.exists(LOG_FILE):
                try:
                    os.remove(LOG_FILE)
                except:
                    pass
            
            # 2. Start Job
            with st.spinner("Starting..."):
                if HAS_SLURM:
                    out = run_command(f"sbatch {JOB_SCRIPT}")
                else:
                    out = start_local(mode_arg)
            # Force reload to update state immediately
            st.sidebar.success(out)
            time.sleep(1)
            st.rerun()

with col_s2:
    if st.button("ğŸ›‘ Stop", help="Stop current training run"):
        with st.spinner("Stopping..."):
            if HAS_SLURM:
                user = os.environ.get("USER", "vavaghad")
                out = run_command(f"scancel -u {user}")
            else:
                out = stop_local()
        st.sidebar.warning(out)
        time.sleep(1)
        st.rerun()

# Section 2: Status
st.sidebar.markdown("---")
st.sidebar.markdown("### 2. Status")

if HAS_SLURM:
    # Auto-check status on refresh
    labels = run_command("squeue --me --format='%.8i %.9P %.8j %.2t %.10M'")
    if labels and "JOBID" in labels:
        st.sidebar.info("ğŸŸ¢ Job Active")
        st.sidebar.code(labels)
    else:
        st.sidebar.caption("âšª No Active Jobs")
else:

    # Global Progress Parsing
    # Read the log file to find our custom "GLOBAL PROGRESS" line
    log_file_path = "local_log.txt" if not HAS_SLURM else None # Slurm logic handled by glob/max below, but simple check here
    
    global_step = 0
    total_steps = 1
    pct = 0.0
    
    # Try to find the log file
    real_log_file = None
    if HAS_SLURM:
         import glob
         files = glob.glob("slurm-*.out")
         if files:
             real_log_file = max(files, key=os.path.getctime)
    elif os.path.exists("local_log.txt"):
         real_log_file = "local_log.txt"
         
    if real_log_file and os.path.exists(real_log_file):
        try:
            # tailored for speed: read last 20 lines
            with open(real_log_file, "rb") as f:
                try:
                    f.seek(-2000, os.SEEK_END)
                except:
                    pass # File too small
                lines = f.readlines()
                for line in reversed(lines):
                    line = line.decode("utf-8", errors="ignore")
                    if "GLOBAL PROGRESS:" in line:
                        # Parse: ğŸŒ GLOBAL PROGRESS: Step 8/42 (19.0%)
                        import re
                        match = re.search(r"Step (\d+)/(\d+)", line)
                        if match:
                            global_step = int(match.group(1))
                            total_steps = int(match.group(2))
                            pct = global_step / total_steps
                        break
        except:
            pass
            
    if global_step > 0:
        st.sidebar.markdown("### ğŸŒ Global Progress")
        st.sidebar.progress(pct, text=f"Step {global_step} of {total_steps}")
    
    status_msg = check_local_status()
    st.sidebar.info(status_msg)

    # Checkpoint Persistence Check
    if os.path.exists("trainer_output"):
        import glob
        ckpts = glob.glob("trainer_output/checkpoint-*")
        if ckpts:
            latest = max(ckpts, key=os.path.getctime)
            ckpt_name = os.path.basename(latest)
            st.sidebar.success(f"ğŸ’¾ Resume Ready: {ckpt_name}")
        else:
            st.sidebar.caption("ğŸ’¾ No checkpoints yet")
    else:
        st.sidebar.caption("ğŸ’¾ No checkpoints found")

if st.sidebar.button("ğŸ”„ Force Refresh"):
    st.rerun()

# --- Live Console Logic (Sidebar) ---
def get_log_content():
    # 1. Determine Log File
    log_file = None
    if HAS_SLURM:
        import glob
        files = glob.glob("slurm-*.out")
        if files:
            log_file = max(files, key=os.path.getctime)
    else:
        if os.path.exists("local_log.txt"):
            log_file = "local_log.txt"
    
    if not log_file:
        return "Waiting for logs..."
    
    try:
        with open(log_file, "r") as f:
            f.seek(0, os.SEEK_END)
            filesize = f.tell()
            if filesize < 5000:
                f.seek(0)
                return f.read()
            else:
                f.seek(max(filesize - 5000, 0))
                return f.read()[-5000:] # Last 5k chars roughly
    except Exception as e:
        return f"Error: {e}"

st.sidebar.markdown("---")
with st.sidebar.expander("ğŸ–¥ï¸ Live Logs", expanded=True):
    st.code(get_log_content(), language="text")



# --- Main: Dashboard ---
st.header("Training Dashboard")

def load_data():
    if not os.path.exists(LOG_FILE):
        return pd.DataFrame(), pd.DataFrame()
    
    metrics = []
    samples = []
    
    try:
        with open(LOG_FILE, "r") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    if data.get("type") == "metrics":
                        metrics.append(data)
                    elif data.get("type") == "sample":
                        samples.append(data)
                except:
                    continue
    except Exception as e:
        pass 
        
    return pd.DataFrame(metrics), pd.DataFrame(samples)

df_metrics, df_samples = load_data()

# 1. Top-Level KPIs (Always Visible)
kpi1, kpi2, kpi3 = st.columns(3)
if not df_metrics.empty:
    latest = df_metrics.iloc[-1]
    cols = df_metrics.columns
    reward_col = next((c for c in cols if "reward" in c or "score" in c), None)
    loss_col = next((c for c in cols if "loss" in c), None)
    
    current_step = int(latest.get("step", 0))
    current_reward = float(latest[reward_col]) if reward_col else 0.0
    current_loss = float(latest[loss_col]) if loss_col else 0.0
    
    kpi1.metric("Current Step", f"{current_step}")
    kpi2.metric("avg Reward", f"{current_reward:.3f}")
    kpi3.metric("Loss", f"{current_loss:.4f}")
else:
    st.info("Waiting for first metrics...")

st.markdown("---")

# 2. Main Visuals in Tabs
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Metrics", "ğŸ“ Samples", "â„¹ï¸ Help"])

with tab1:
    if not df_metrics.empty:
        c1, c2 = st.columns(2)
        if reward_col:
            c1.subheader("Reward History")
            chart_r = alt.Chart(df_metrics).mark_line(color='green').encode(
                x='step', y=alt.Y(reward_col, title='Reward'), tooltip=['step', reward_col]
            ).interactive()
            c1.altair_chart(chart_r, use_container_width=True)
            
        kl_col = next((c for c in cols if "kl" in c), None)
        if kl_col:
            c2.subheader("KL Divergence")
            chart_k = alt.Chart(df_metrics).mark_line(color='orange').encode(
                x='step', y=alt.Y(kl_col, title='KL Div'), tooltip=['step', kl_col]
            ).interactive()
            c2.altair_chart(chart_k, use_container_width=True)
    else:
        st.write("Charts will appear here once training starts.")

with tab2:
    if not df_samples.empty:
        recent = df_samples.tail(10)[::-1]
        for i, row in recent.iterrows():
            r_val = row.get('reward', 0.0)
            color = "ğŸŸ¢" if r_val > 0.5 else "ğŸ”´"
            with st.expander(f"{color} Reward: {r_val:.2f} | Q: {row.get('question', '')[:50]}..."):
                st.markdown(f"**Question:** {row.get('question')}")
                st.markdown(f"**Answer:** {row.get('response')}")
                st.caption(f"Step {row.get('step', '?')}")
    else:
        st.write("No samples yet.")

with tab3:
    st.markdown("""
    ### How to Use
    1. **Start**: Use the Sidebar (left) to click "â–¶ï¸ Start Local" (Mac) or "Start Job" (Cluster).
    2. **Monitor**:
       - **Live Logs (Sidebar)**: Watch the raw terminal output (downloads, errors).
       - **Metrics (Here)**: Watch the reward go UP and loss go DOWN.
       - **Samples (Tab 2)**: Read the actual Q&A the model is generating.
    3. **Stop**: Click "ğŸ›‘ Stop" in the sidebar when done.
    """)

# Auto Refresh logic at bottom
if st.checkbox("Auto-Refresh (2s)", value=True):
    time.sleep(2)
    st.rerun()

